// Package src provides Phase 1 integration testing for the API latency optimizer.
// This module validates that all Phase 1 components work together correctly.
package main

import (
	"fmt"
	"log"
	"net/http"
	"testing"
	"time"
)

// Phase1IntegrationTest validates the complete Phase 1 optimization stack
func TestPhase1Integration(t *testing.T) {
	log.Println("ðŸš€ Starting Phase 1 Integration Test")

	// Test target (using a reliable test endpoint)
	testURL := "https://httpbin.org/get"

	// Create default configuration
	config := DefaultIntegratedConfig()
	config.BenchmarkConfig = &BenchmarkConfig{
		TotalRequests:  50,  // Smaller test for faster execution
		Concurrency:    5,   // Lower concurrency for stability
		RequestTimeout: 30 * time.Second,
	}

	// Disable monitoring for test to avoid port conflicts
	config.MonitoringConfig.Enabled = false

	t.Run("OptimizedClientCreation", func(t *testing.T) {
		client, err := NewOptimizedClient(config.ClientConfig)
		if err != nil {
			t.Fatalf("Failed to create optimized client: %v", err)
		}

		if !client.IsInitialized() {
			t.Error("Client not properly initialized")
		}

		defer client.Stop()
		log.Println("âœ“ Optimized client created successfully")
	})

	t.Run("BasicOptimizedRequest", func(t *testing.T) {
		client, err := NewOptimizedClient(config.ClientConfig)
		if err != nil {
			t.Fatalf("Failed to create optimized client: %v", err)
		}
		defer client.Stop()

		// Create test request
		req, err := http.NewRequest("GET", testURL, nil)
		if err != nil {
			t.Fatalf("Failed to create request: %v", err)
		}

		optimizedReq := &OptimizedRequest{
			Request:       req,
			UseCache:      true,
			EnableMetrics: true,
		}

		// Execute request
		resp, err := client.Do(optimizedReq)
		if err != nil {
			t.Fatalf("Request failed: %v", err)
		}
		defer resp.Response.Body.Close()

		// Validate response
		if resp.Response.StatusCode != 200 {
			t.Errorf("Expected status 200, got %d", resp.Response.StatusCode)
		}

		if resp.TotalLatency <= 0 {
			t.Error("Invalid latency measurement")
		}

		log.Printf("âœ“ Basic request completed in %v", resp.TotalLatency)
	})

	t.Run("CacheEffectiveness", func(t *testing.T) {
		client, err := NewOptimizedClient(config.ClientConfig)
		if err != nil {
			t.Fatalf("Failed to create optimized client: %v", err)
		}
		defer client.Stop()

		// Make multiple requests to the same URL to test caching
		req, err := http.NewRequest("GET", testURL, nil)
		if err != nil {
			t.Fatalf("Failed to create request: %v", err)
		}

		var latencies []time.Duration

		for i := 0; i < 5; i++ {
			optimizedReq := &OptimizedRequest{
				Request:       req,
				UseCache:      true,
				EnableMetrics: true,
			}

			resp, err := client.Do(optimizedReq)
			if err != nil {
				t.Fatalf("Request %d failed: %v", i, err)
			}
			resp.Response.Body.Close()

			latencies = append(latencies, resp.TotalLatency)

			// Log cache hit status
			if resp.CacheHit {
				log.Printf("âœ“ Request %d: Cache HIT (%v)", i, resp.TotalLatency)
			} else {
				log.Printf("â—‹ Request %d: Cache MISS (%v)", i, resp.TotalLatency)
			}
		}

		// Check if we had any cache hits
		stats := client.GetStats()
		if stats.CacheHits == 0 {
			t.Error("Expected at least one cache hit")
		}

		log.Printf("âœ“ Cache performance: %.1f%% hit ratio", stats.CacheHitRatio*100)
	})

	t.Run("MiniPerformanceBenchmark", func(t *testing.T) {
		// Create a mini benchmark to validate performance improvements
		log.Println("Running mini performance benchmark...")

		// Test configuration
		runConfig := &BenchmarkRunConfig{
			URL:              testURL,
			TotalRequests:    20,
			Concurrency:      3,
			Timeout:          30 * time.Second,
			UseOptimizations: true,
		}

		// Create benchmark engine
		benchmarkConfig := &BenchmarkConfig{
			TotalRequests:  runConfig.TotalRequests,
			Concurrency:    runConfig.Concurrency,
			RequestTimeout: runConfig.Timeout,
		}

		engine, err := NewBenchmarkEngine(benchmarkConfig)
		if err != nil {
			t.Fatalf("Failed to create benchmark engine: %v", err)
		}

		// Run benchmark
		result, err := engine.Run(runConfig)
		if err != nil {
			t.Fatalf("Benchmark failed: %v", err)
		}

		// Validate results
		if result.SuccessRate < 90 {
			t.Errorf("Low success rate: %.2f%%", result.SuccessRate)
		}

		if result.Latency.P50 <= 0 {
			t.Error("Invalid P50 latency")
		}

		log.Printf("âœ“ Mini benchmark completed:")
		log.Printf("  - P50 Latency: %v", result.Latency.P50)
		log.Printf("  - P95 Latency: %v", result.Latency.P95)
		log.Printf("  - Throughput: %.2f req/s", result.Throughput.RequestsPerSecond)
		log.Printf("  - Success Rate: %.2f%%", result.SuccessRate)

		// Check if we meet Phase 1 targets (relaxed for test)
		if result.Latency.P50 > 500*time.Millisecond {
			t.Errorf("P50 latency too high: %v (expected < 500ms)", result.Latency.P50)
		}

		if result.Throughput.RequestsPerSecond < 10 {
			t.Errorf("Throughput too low: %.2f req/s (expected > 10)", result.Throughput.RequestsPerSecond)
		}
	})

	log.Println("ðŸŽ‰ Phase 1 Integration Test completed successfully!")
}

// BenchmarkOptimizedClient benchmarks the optimized client performance
func BenchmarkOptimizedClient(b *testing.B) {
	testURL := "https://httpbin.org/get"

	config := DefaultOptimizedClientConfig()
	config.MonitoringConfig.Enabled = false // Disable monitoring for benchmarks

	client, err := NewOptimizedClient(config)
	if err != nil {
		b.Fatalf("Failed to create client: %v", err)
	}
	defer client.Stop()

	req, err := http.NewRequest("GET", testURL, nil)
	if err != nil {
		b.Fatalf("Failed to create request: %v", err)
	}

	b.ResetTimer()

	b.RunParallel(func(pb *testing.PB) {
		for pb.Next() {
			optimizedReq := &OptimizedRequest{
				Request:       req,
				UseCache:      true,
				EnableMetrics: false, // Disable metrics for pure performance test
			}

			resp, err := client.Do(optimizedReq)
			if err != nil {
				b.Errorf("Request failed: %v", err)
				continue
			}
			resp.Response.Body.Close()
		}
	})
}

// runPhase1ValidationSuite runs a comprehensive validation of Phase 1 components
func runPhase1ValidationSuite() error {
	log.Println("ðŸ” Starting Phase 1 Validation Suite")

	validationResults := make(map[string]bool)

	// Test 1: Component initialization
	log.Println("Testing component initialization...")
	if err := validateComponentInitialization(); err != nil {
		log.Printf("âŒ Component initialization failed: %v", err)
		validationResults["component_init"] = false
	} else {
		log.Println("âœ… Component initialization passed")
		validationResults["component_init"] = true
	}

	// Test 2: HTTP/2 functionality
	log.Println("Testing HTTP/2 functionality...")
	if err := validateHTTP2Functionality(); err != nil {
		log.Printf("âŒ HTTP/2 functionality failed: %v", err)
		validationResults["http2"] = false
	} else {
		log.Println("âœ… HTTP/2 functionality passed")
		validationResults["http2"] = true
	}

	// Test 3: Cache performance
	log.Println("Testing cache performance...")
	if err := validateCachePerformance(); err != nil {
		log.Printf("âŒ Cache performance failed: %v", err)
		validationResults["cache"] = false
	} else {
		log.Println("âœ… Cache performance passed")
		validationResults["cache"] = true
	}

	// Test 4: End-to-end performance
	log.Println("Testing end-to-end performance...")
	if err := validateEndToEndPerformance(); err != nil {
		log.Printf("âŒ End-to-end performance failed: %v", err)
		validationResults["e2e_performance"] = false
	} else {
		log.Println("âœ… End-to-end performance passed")
		validationResults["e2e_performance"] = true
	}

	// Calculate overall results
	passed := 0
	total := len(validationResults)

	for _, result := range validationResults {
		if result {
			passed++
		}
	}

	successRate := float64(passed) / float64(total)

	log.Printf("\nðŸ“Š Phase 1 Validation Results:")
	log.Printf("   Tests Passed: %d/%d (%.1f%%)", passed, total, successRate*100)

	if successRate >= 0.8 {
		log.Println("ðŸŽ‰ Phase 1 validation PASSED - Ready for production!")
		return nil
	} else {
		return fmt.Errorf("phase 1 validation FAILED - only %.1f%% of tests passed", successRate*100)
	}
}

// validateComponentInitialization tests if all components can be initialized
func validateComponentInitialization() error {
	config := DefaultIntegratedConfig()
	config.MonitoringConfig.Enabled = false

	client, err := NewOptimizedClient(config.ClientConfig)
	if err != nil {
		return fmt.Errorf("failed to create optimized client: %w", err)
	}
	defer client.Stop()

	if !client.IsInitialized() {
		return fmt.Errorf("client not properly initialized")
	}

	return nil
}

// validateHTTP2Functionality tests HTTP/2 specific features
func validateHTTP2Functionality() error {
	// For now, just test that we can make requests
	// In a full implementation, we'd test HTTP/2 specific features
	config := DefaultOptimizedClientConfig()
	config.MonitoringConfig.Enabled = false

	client, err := NewOptimizedClient(config)
	if err != nil {
		return fmt.Errorf("failed to create client: %w", err)
	}
	defer client.Stop()

	req, err := http.NewRequest("GET", "https://httpbin.org/get", nil)
	if err != nil {
		return fmt.Errorf("failed to create request: %w", err)
	}

	optimizedReq := &OptimizedRequest{
		Request:       req,
		UseCache:      false, // Test direct HTTP/2 without cache
		EnableMetrics: false,
	}

	resp, err := client.Do(optimizedReq)
	if err != nil {
		return fmt.Errorf("HTTP/2 request failed: %w", err)
	}
	defer resp.Response.Body.Close()

	if resp.Response.StatusCode != 200 {
		return fmt.Errorf("unexpected status code: %d", resp.Response.StatusCode)
	}

	return nil
}

// validateCachePerformance tests cache hit ratios and performance
func validateCachePerformance() error {
	config := DefaultOptimizedClientConfig()
	config.MonitoringConfig.Enabled = false

	client, err := NewOptimizedClient(config)
	if err != nil {
		return fmt.Errorf("failed to create client: %w", err)
	}
	defer client.Stop()

	testURL := "https://httpbin.org/get"

	// Make multiple requests to the same URL
	for i := 0; i < 3; i++ {
		req, err := http.NewRequest("GET", testURL, nil)
		if err != nil {
			return fmt.Errorf("failed to create request: %w", err)
		}

		optimizedReq := &OptimizedRequest{
			Request:       req,
			UseCache:      true,
			EnableMetrics: false,
		}

		resp, err := client.Do(optimizedReq)
		if err != nil {
			return fmt.Errorf("cached request failed: %w", err)
		}
		resp.Response.Body.Close()
	}

	// Check cache performance
	stats := client.GetStats()
	if stats.CacheHits == 0 {
		return fmt.Errorf("no cache hits recorded")
	}

	if stats.CacheHitRatio < 0.5 {
		return fmt.Errorf("cache hit ratio too low: %.2f", stats.CacheHitRatio)
	}

	return nil
}

// validateEndToEndPerformance tests overall system performance
func validateEndToEndPerformance() error {
	config := &BenchmarkConfig{
		TotalRequests:  10,
		Concurrency:    2,
		RequestTimeout: 30 * time.Second,
	}

	engine, err := NewBenchmarkEngine(config)
	if err != nil {
		return fmt.Errorf("failed to create benchmark engine: %w", err)
	}

	runConfig := &BenchmarkRunConfig{
		URL:              "https://httpbin.org/get",
		TotalRequests:    10,
		Concurrency:      2,
		Timeout:          30 * time.Second,
		UseOptimizations: true,
	}

	result, err := engine.Run(runConfig)
	if err != nil {
		return fmt.Errorf("benchmark failed: %w", err)
	}

	// Validate performance requirements (relaxed for testing)
	if result.SuccessRate < 80 {
		return fmt.Errorf("success rate too low: %.2f%%", result.SuccessRate)
	}

	if result.Latency.P50 > time.Second {
		return fmt.Errorf("P50 latency too high: %v", result.Latency.P50)
	}

	if result.Throughput.RequestsPerSecond < 5 {
		return fmt.Errorf("throughput too low: %.2f req/s", result.Throughput.RequestsPerSecond)
	}

	return nil
}

// Phase1ValidationReport generates a comprehensive Phase 1 validation report
func Phase1ValidationReport() string {
	return `
# Phase 1 API Latency Optimization - Validation Report

## Executive Summary
This report validates the completion and effectiveness of Phase 1 optimization components.

## Component Status
- âœ… HTTP/2 Client: Implemented with connection pooling
- âœ… Caching System: LRU cache with intelligent policies
- âœ… Monitoring Framework: Real-time metrics and alerting
- âœ… Integration Layer: Unified optimization client

## Performance Targets
- **Latency Target**: < 100ms P50 (Production target)
- **Cache Hit Ratio**: > 60%
- **Connection Reuse**: > 90%
- **Throughput**: > 50 req/s

## Validation Results
Run 'go test -v' to execute comprehensive validation suite.

## Next Steps
Upon successful Phase 1 validation:
1. Deploy to staging environment
2. Run extended performance testing
3. Begin Phase 2 planning (Advanced optimizations)
4. Monitor production performance

*Generated by Phase 1 Integration Test Suite*
`
}